---
layout: single
title: Linear Logic Gates with Perceptron (Draft - WiP)
permalink: /projects/linear-logic-gates-with-perceptron
---

# Introduction

**Goal:** To create a model of linear logic gates in Python using perceptron algorithm and NumPy and compare its behaviour to that of a similar model created previously.

**Purpose:** To demonstrate the problem-solving and decision-making processes, as well as enhance the understanding of neural networks’ most basic components and their implementation in Python.

**Previous Model (perceptron 1)**
The model is based on the mathematical description of the perceptron from Artificial Neural Networks (ANNs) course. Built without Large Language Model (LLM) assistance.
- [Code](url-to-code)

**New Model (perceptron 2)**
GPT-4 was used to generate bulk of the code to experiment with LLM assistance.
- [Code](url-to-code)

**Logic gates (AND, OR)**

A logic gate is a Boolean function performed on a set of binary inputs to produce a single binary output:

| A | B | AND | OR |
|---|---|-----|----|
| 0 | 0 |  0  | 0  |
| 0 | 1 |     | 1  |
| 1 | 0 |     |    |
| 1 | 1 |  1  |    |

AND, OR logic gates can be modelled by plotting a single straight line (‘hyperplane’ or ‘decision boundary’) and classifying inputs lying on one side as AND, OR gate respectively.

**Theoretical Principles Behind Perceptron**
Out of scope (see [Wiki](url-to-wiki)).

# Perceptron 2

## Initial Model Development

**Steps**:

1. Initial algorithm generated by GPT-4
2. Algorithm tested for code and prediction errors – no errors encountered
3. Detailed algorithm explanation by GPT-4 and follow up questions until every block’s purpose was understood
4. Early stoppage added using GPT-4 as the algorithm was bound to converge due to linear data separability (see the graphs above)
5. Decision boundary plot added using GPT-4

## Initial Model Analysis

The decision boundary plot surfaced that:

- The final weights (and therefore the decision boundary) differed from perceptron 1
- The positive class lied on the decision boundary (unlike with perceptron 1)
- Adjusting the learning rate only affected the weight vector magnitude (and not the decision boundary)

## Perceptron 2 & 1 Weight Difference Analysis

Potential factors contributing to weight differences between Perceptron 1 & 2 were assessed and ruled out:

- Sample order
- Initial weight/bias
- Learning rate

Despite slight differences in implementation, both models used the same weight update formula: `w ± x_i`. However, tracking weight/bias updates revealed alignment in both algorithms only until step 11, when Perceptron 2 prematurely stopped updating.

**Perceptron 2**

1. Bias after update: -1, weights after update: [0. 0.]
2. Bias after update: 0, weights after update: [1. 1.]
3. Bias after update: -1, weights after update: [1. 1.]
4. Bias after update: -2, weights after update: [0. 1.]
5. Bias after update: -1, weights after update: [1. 2.]
6. Bias after update: -2, weights after update: [0. 2.]
7. Bias after update: -3, weights after update: [0. 1.]
8. Bias after update: -2, weights after update: [1. 2.]
9. Bias after update: -3, weights after update: [1. 1.]
10. Bias after update: -2, weights after update: [2. 2.]
11. Bias after update: -3, weights after update: [1. 2.]

**Perceptron 1**

1. [[-1  0  0]]
2. [[0 1 1]]
3. [[-1  1  1]]
4. [[-2  0  1]]
5. [[-1  1  2]]
6. [[-2  0  2]]
7. [[-3  0  1]]
8. [[-2  1  2]]
9. [[-3  1  1]]
10. [[-2  2  2]]
11. [[-3  1  2]]
12. [[-2  2  3]]
13. [[-3  1  3]]
14. [[-4  1  2]]
15. [[-3  2  3]]
16. [[-4  2  2]]
17. [[-3  3  3]]
18. [[-4  2  3]]

The fact that points lie on the decision boundary in Perceptron 2 didn't impact model performance due to the limited input scope and binary outputs. However, this behaviour wasn't exhibited by Perceptron 1, necessitating a deeper investigation.

The key distinguishing factor between the error functions of the two models was that Perceptron 2 utilised an activation function for predictions, while Perceptron 1 directly used neuron output.

Additionally, even if Perceptron’s 2 activation function (unit step function) outputted 0 for a point on the decision boundary (`return np.where(x>0, 1, 0)`), it would match the 'correct' label '0', resulting in zero residual for negative class and no weight update.

```python
# Perceptron update rule
update = self.lr * (y_[idx] - y_predicted) # Residual
if update != 0:
    # proceed with weight update
```

On the other hand, Perceptron 1 used (-1, 1) labels while also utilising a ‘sign based’ error function, enabling a weight update with a neuron output of 0. Adopting a similar error function and labelling mechanism in Perceptron 2 could lead to complications:

- The error function should utilise the activation function, not the neuron output.
- Introducing a 'sign function' as the activation function would shift the prediction range from (0, 1) to (-1, 1), which could pose potential system compatibility issues.

In response, Perceptron 2 retained a slightly modified activation function: `return np.where(x>0, 1, 0)` instead of `return np.where(x>=0, 1, 0)`. Additionally, a conditional line was incorporated to assign a (-1) residual to the negative class on the decision boundary.

```python
if linear_output == 0 and y_[idx] == 0:
    update = self.lr * (-1)
```

This modification mirrored Perceptron 1's decision boundary evolution in Perceptron 2, aligning their final decision boundaries and total training steps (tested using AND, OR gates).

# Perceptron 2 Activation Function Update

Adding a condition to the error function seemed like an inelegant solution, introducing complexity and preventing the calculation of residuals with a single mathematical expression.

Previously, GPT-4 had advised that in the case of binary probabilistic activation functions (such as sigmoid activation function) the points on the decision boundary could output 0.5 (50%). 

This concept seemed appropriate for Perceptron’s 2 activation function as well, with a boundary point producing an output of 0.5, situated between 0 and 1. Residuals in the range (-0.5, 0.5) preserved the 'direction' of the required update, and the magnitude of the update was scaled by 0.5, reflecting that points on the decision boundary would typically require smaller updates for correct classification.

The algorithm implementation on Wiki had an activation function identical to Perceptron’s 2, i.e., `return np.where(x>0, 1, 0)`. But further examination of the unit step function used as the activation function showed that it could yield either 0, 0.5, or 1 for an input of 0, depending on interpretation. This flexibility meant we could extend the activation function output without changing the function type itself.

The initial attempt to include the additional condition by rewriting the `np.where(x>0, 1, 0)` function in an if/elif/else format resulted in an error when the 'predict' method was invoked from the Perceptron class instance. This issue arose because while the 'fit' method passed a float to the activation function, 'predict' passed an array (all samples at once).

The simplest solution seemed to add additional condition to the existing np.where  function. GPT-4 customised the existing `return np.where(x>0, 1, 0)` by introducing a nested condition, thus resolving the compatibility issue.

```python
return np.where(x < 0, 0, 
                       np.where(x == 0, 0.5, 1))
```	